[config]
save_dir = "continuous_classic_control/acrobot/proximal_mdccem_backward_clipping"
save_backend = "jld2"
exp_file = "./experiment/continuous_default.jl"
exp_module_name = "DefaultContinuousExperiment"
exp_func_name = "main_experiment"
arg_iter_type = "iterV2"

####################################################################
# Static Args
####################################################################
[static_args]
steps = 100000

####################################################################
# Environment
####################################################################
[static_args.env]
type = "Acrobot"
step_limit = 1000

[static_args.env.kwargs]
"γ" = 0.99
continuous = true

####################################################################
# Agent
####################################################################
[sweep_args.agent]
"τ" = [0e0, 1e-2, 1e-1]
"λ" = [1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3]

[static_args.agent]
type = "BatchQAgent"
batch_size = 32
steps_before_learning = 1000
actor_update_ratio = [10, 10]
critic_update_ratio = [1, 1]
device = "cpu"
num_md_updates = 10
forward_direction = false

[static_args.agent.actor]

[static_args.agent.actor.policy]
type = "ArctanhNormalPolicy"

[static_args.agent.actor.policy.approx]
type = "Lux"
init = "glorot_uniform"
act = ["relu", "relu"]
hidden = [64, 64]

[static_args.agent.actor.optim]
type = "Adam"

[sweep_args.agent.actor.optim]
"η_scale" = [1e-1, 1e0, 1e1]

[static_args.agent.actor.update]
type = "ContinuousProximalMDCCEM"
n = 10
"ρs" = [0.1, 0.2]
num_samples = 1

[sweep_args.agent.actor.update]
clip = [0.2, 0.5, 0.7]

[static_args.agent.critic]

[static_args.agent.critic.value_fn]
type = "Q"
n = 1

[static_args.agent.critic.value_fn.approx]
type = "Lux"
init = "glorot_uniform"
act = ["relu", "relu"]
hidden = [64, 64]

[static_args.agent.critic.optim]
type = "Adam"

[sweep_args.agent.critic.optim]
"η" = [1e-4, 1e-3, 1e-2]

[static_args.agent.critic.update]
type = "Sarsa"
regularisers = [
    {type = "EntropyBellmanRegulariser"},
]

[static_args.agent.buffer]
type = "ExperienceReplay"
capacity = 100000

[static_args.agent.target]
polyak = 0.01
refresh_interval = 1

####################################################################
# Sweep Args
####################################################################
[sweep_args]
seed = "1:50"
